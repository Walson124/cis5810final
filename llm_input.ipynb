{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19d2f6a3",
   "metadata": {},
   "source": [
    "Install Ollama runtime if not already installed\n",
    "\n",
    "We'll use Phi-3-mini for okayish performance, but quantized version for space reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c0bb035",
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "import subprocess\n",
    "import shutil\n",
    "import os\n",
    "import tempfile\n",
    "import subprocess\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "269c1e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Ollama already installed.\n"
     ]
    }
   ],
   "source": [
    "def install_ollama():\n",
    "    system = platform.system().lower()\n",
    "\n",
    "    if shutil.which(\"ollama\"):\n",
    "        print(\"‚úÖ Ollama already installed.\")\n",
    "        return\n",
    "\n",
    "    print(f\"üõ†Ô∏è Installing Ollama for {system}...\")\n",
    "\n",
    "    if \"windows\" in system:\n",
    "        url = \"https://ollama.com/download/OllamaSetup.exe\"\n",
    "        tmpfile = os.path.join(tempfile.gettempdir(), \"OllamaSetup.exe\")\n",
    "        print(\"Downloading Ollama installer...\")\n",
    "        urllib.request.urlretrieve(url, tmpfile)\n",
    "        print(\"Running installer (you may need to approve it)...\")\n",
    "        subprocess.run([\"start\", \"/wait\", tmpfile], shell=True)\n",
    "        print(\"‚ö†Ô∏è After installation, please restart your notebook or terminal once if Ollama doesn‚Äôt start automatically.\")\n",
    "\n",
    "    elif \"darwin\" in system or \"linux\" in system:\n",
    "        # Works for macOS (darwin) and Linux\n",
    "        subprocess.run(\"curl -fsSL https://ollama.com/install.sh | sh\", shell=True, check=False)\n",
    "        print(\"‚úÖ Ollama install script completed.\")\n",
    "\n",
    "    else:\n",
    "        print(f\"‚ùå Unsupported OS: {system}\")\n",
    "\n",
    "# Run it\n",
    "install_ollama()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25339b16",
   "metadata": {},
   "source": [
    "Make sure to add Ollama to path\n",
    "\n",
    "Pull phi-3-mini model\n",
    "\n",
    "Make sure you have ollama added to path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a500c59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†ã \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†ô \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 633fc5be925f: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè 2.2 GB                         \u001b[K\n",
      "pulling fa8235e5b48f: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè 1.1 KB                         \u001b[K\n",
      "pulling 542b217f179c: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  148 B                         \u001b[K\n",
      "pulling 8dde1baf1db0: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   78 B                         \u001b[K\n",
      "pulling 23291dc44752: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  483 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "!ollama pull phi3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5a440a",
   "metadata": {},
   "source": [
    "Model run helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcd9f972",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_cli(prompt: str, model=\"phi3\"):\n",
    "    \"\"\"\n",
    "    Run an Ollama model using the CLI (Command Line Interface)\n",
    "    and return the plaintext response.\n",
    "    \n",
    "    The prompt is passed as a final argument to the 'ollama run' command.\n",
    "    \"\"\"\n",
    "    # 1. Corrected Command: Pass prompt as argument, remove --json\n",
    "    model_name = \"phi3\"\n",
    "    message_content = prompt\n",
    "\n",
    "    try:\n",
    "        response = ollama.generate(\n",
    "            model=model_name,\n",
    "            prompt=message_content\n",
    "        )\n",
    "        # The 'response' object has a 'response' key for the output text\n",
    "        print(f\"Phi-3: {response['response']}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26eccd0a",
   "metadata": {},
   "source": [
    "Prompt user for input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e672d450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phi-3: In this command, a person is instructing to animate an acorn moving laterally through their display or interface area, resembling flight without lifting off from its original position in the virtual environment created by Unreal Engine's blueprint. The direction of movement should be side-to-side (left and right), covering as much horizontal space on the screen as possible while maintaining an upward trajectory to avoid touching a designated 'ground'.\n",
      "Search query: None\n"
     ]
    }
   ],
   "source": [
    "user_input = input(\"Describe your scene or animation: \")\n",
    "prompt = f\"\"\"\n",
    "Summarize the action in the user's prompt. Don't focus on the object, just the movement.\n",
    "\n",
    "User prompt: {user_input}\n",
    "\"\"\"\n",
    "\n",
    "query = run_model_cli(prompt)\n",
    "print(\"Search query:\", query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d5d885",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
